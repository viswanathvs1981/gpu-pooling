#!/bin/bash

set -uo pipefail

GREEN='\033[0;32m'
BLUE='\033[0;34m'
YELLOW='\033[1;33m'
NC='\033[0m'

success() { echo -e "${GREEN}âœ… $1${NC}"; }
info() { echo -e "${BLUE}â„¹ï¸  $1${NC}"; }
warn() { echo -e "${YELLOW}âš ï¸  $1${NC}"; }

banner() {
cat <<'EOF'
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘     USE CASE 10: Azure Cloud Bursting & Auto-Scaling          â•‘
â•‘     Problem: Handle traffic spikes without over-provisioning   â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
EOF
}

cleanup() {
  info "ğŸ§¹ Cleaning up test resources..."
  kubectl delete azuregpusource demo-burst-source --ignore-not-found=true >/dev/null 2>&1 || true
  success "Cleanup complete"
}

trap cleanup EXIT

banner
echo ""

info "ğŸ“– This demo shows:"
echo "   â€¢ Hybrid on-prem + cloud architecture"
echo "   â€¢ Automatic cloud bursting during peak load"
echo "   â€¢ Cost-optimized scaling (spot instances)"
echo "   â€¢ Multi-region GPU federation"
echo "   â€¢ Azure GPU source configuration"
echo ""
sleep 2

# Step 1: The Problem
info "âŒ Step 1: The Traditional Scaling Problem"
echo ""
echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
echo "Scenario: AI platform with variable load"
echo ""
echo "  Baseline: 10 users (2 GPUs needed)"
echo "  Peak: 100 users (20 GPUs needed)"
echo "  Peak duration: 2 hours/day"
echo ""
echo "Traditional Solutions:"
echo ""
echo "  Option 1: Provision for peak (20 GPUs 24/7)"
echo "    â€¢ Cost: 20 Ã— \$3/hour Ã— 720 hours = \$43,200/month"
echo "    â€¢ Utilization: 10% (18 GPUs idle 22 hours/day)"
echo "    â€¢ Waste: \$38,880/month (90%)"
echo ""
echo "  Option 2: Provision for baseline (2 GPUs)"
echo "    â€¢ Cost: 2 Ã— \$3/hour Ã— 720 hours = \$4,320/month"
echo "    â€¢ Peak problem: 90% of requests fail"
echo "    â€¢ User experience: âŒ Poor"
echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
echo ""
sleep 3

# Step 2: Cloud Bursting Solution
info "âœ… Step 2: Cloud Bursting Solution"
echo ""
echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
echo "Hybrid Architecture:"
echo ""
echo "  On-Premises / Reserved:"
echo "    â€¢ 2 GPUs (always on for baseline)"
echo "    â€¢ Cost: \$4,320/month"
echo "    â€¢ Handles: Normal load (90% of time)"
echo ""
echo "  Cloud Burst (Azure Spot):"
echo "    â€¢ 18 GPUs (only during peak)"
echo "    â€¢ Duration: 2 hours/day Ã— 30 days = 60 hours/month"
echo "    â€¢ Spot pricing: \$1.20/hour (60% discount)"
echo "    â€¢ Cost: 18 Ã— \$1.20 Ã— 60 = \$1,296/month"
echo ""
echo "  Total Cost: \$4,320 + \$1,296 = \$5,616/month"
echo "  vs Always-Peak: \$43,200/month"
echo "  Savings: \$37,584/month (87%) ğŸ‰"
echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
echo ""
sleep 3

# Step 3: Azure GPU Source CRD
info "ğŸš€ Step 3: Configuring Azure GPU Source"
echo ""
echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
AZURE_SOURCE_COUNT=$(kubectl get azuregpusource --all-namespaces --no-headers 2>/dev/null | wc -l | tr -d ' ')

if [ "$AZURE_SOURCE_COUNT" -gt 0 ]; then
  success "Azure GPU sources found: $AZURE_SOURCE_COUNT"
  echo ""
  kubectl get azuregpusource --all-namespaces 2>/dev/null
else
  info "Creating example Azure GPU source configuration..."
  echo ""
fi

cat <<EOF | kubectl apply -f - >/dev/null 2>&1
apiVersion: tensor-fusion.ai/v1
kind: AzureGPUSource
metadata:
  name: demo-burst-source
  namespace: default
spec:
  # Azure Configuration
  subscriptionID: "your-subscription-id"
  resourceGroup: "tensor-fusion-burst-rg"
  location: "eastus"
  
  # VM Configuration
  vmSize: "Standard_NC6s_v3"  # Tesla V100
  priority: "Spot"  # 60-90% cheaper
  maxPrice: "1.50"  # Max spot price
  
  # Scaling Configuration
  minInstances: 0
  maxInstances: 20
  scaleUpThreshold: 0.80    # Scale up at 80% utilization
  scaleDownThreshold: 0.30  # Scale down at 30% utilization
  cooldownPeriod: "5m"
  
  # Cost Controls
  maxMonthlyCost: "2000"  # Budget limit
  enableCostAlerts: true
  
  # Network
  virtualNetwork: "aks-vnet"
  subnet: "burst-subnet"
  
  # Auto-provisioning
  autoProvision: true
  healthCheckInterval: "30s"
EOF

success "Azure GPU source configured!"
echo ""
sleep 2

# Step 4: Scaling Workflow
info "âš¡ Step 4: Auto-Scaling Workflow"
echo ""
echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
echo "Time: 8:00 AM - Traffic starts increasing"
echo ""
echo "  Step 1: Monitor detects 75% GPU utilization"
echo "  Step 2: Threshold exceeded (> 80%)"
echo "  Step 3: Azure GPU Source triggers scale-up"
echo "  Step 4: Azure provisions 5Ã— NC6s_v3 spot instances"
echo "  Step 5: VMs join cluster (~3 minutes)"
echo "  Step 6: Tensor Fusion discovers new GPUs"
echo "  Step 7: Workloads distributed across 7 total GPUs"
echo "  Step 8: Utilization drops to 60%"
echo ""
echo "Time: 10:00 AM - Traffic subsides"
echo ""
echo "  Step 1: Monitor detects 25% GPU utilization"
echo "  Step 2: Below threshold (< 30%)"
echo "  Step 3: Cooldown period (5 min) expires"
echo "  Step 4: Azure GPU Source triggers scale-down"
echo "  Step 5: Drain workloads from cloud GPUs"
echo "  Step 6: Deallocate 5 spot instances"
echo "  Step 7: Back to 2 baseline GPUs"
echo "  Step 8: Cost accumulation stops"
echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
echo ""
sleep 3

# Step 5: Real-world scenarios
info "ğŸŒ Step 5: Real-World Scenarios"
echo ""
echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
echo "Scenario 1: E-commerce AI during Black Friday"
echo "  â€¢ Baseline: 5 GPUs year-round"
echo "  â€¢ Black Friday week: Burst to 50 GPUs"
echo "  â€¢ Duration: 7 days"
echo "  â€¢ Cost: \$10,800 baseline + \$3,024 burst = \$13,824"
echo "  â€¢ vs Always-50: \$108,000/month"
echo "  â€¢ Savings: \$94,176 (87%)"
echo "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€"
echo ""
echo "Scenario 2: Research team with batch training jobs"
echo "  â€¢ Baseline: 2 GPUs for experiments"
echo "  â€¢ Training runs: Burst to 32 GPUs"
echo "  â€¢ Frequency: 3Ã— per week, 4 hours each"
echo "  â€¢ Monthly burst: 48 hours"
echo "  â€¢ Cost: \$4,320 baseline + \$1,843 burst = \$6,163"
echo "  â€¢ vs Always-32: \$69,120"
echo "  â€¢ Savings: \$62,957 (91%)"
echo "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€"
echo ""
echo "Scenario 3: Startup with unpredictable growth"
echo "  â€¢ Start: 1 GPU"
echo "  â€¢ Week 1-4: Gradual burst to 3 GPUs"
echo "  â€¢ Week 5-8: Burst to 8 GPUs"
echo "  â€¢ Auto-scaling handles organic growth"
echo "  â€¢ No manual provisioning needed"
echo "  â€¢ Pay only for actual usage"
echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
echo ""
sleep 3

# Step 6: Multi-region federation
info "ğŸŒ Step 6: Multi-Region Federation"
echo ""
echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
echo "Global Architecture:"
echo ""
echo "  Primary Cluster (East US):"
echo "    â€¢ 10 GPUs baseline"
echo "    â€¢ Handles: US & Europe traffic"
echo ""
echo "  Burst Regions (configured via AzureGPUSource):"
echo "    â€¢ West US: 0-20 GPUs (low latency for US West)"
echo "    â€¢ North Europe: 0-15 GPUs (GDPR compliance)"
echo "    â€¢ Southeast Asia: 0-10 GPUs (APAC traffic)"
echo ""
echo "  Intelligent Routing:"
echo "    â€¢ Latency-based: Route to nearest GPU"
echo "    â€¢ Compliance: Keep EU data in EU"
echo "    â€¢ Cost-based: Prefer cheaper regions"
echo "    â€¢ Failover: Auto-switch if region down"
echo ""
echo "  Benefits:"
echo "    âœ“ < 100ms global latency"
echo "    âœ“ Data sovereignty compliance"
echo "    âœ“ 99.99% availability"
echo "    âœ“ Optimal cost per region"
echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
echo ""
sleep 3

# Step 7: Spot instance handling
info "ğŸ’° Step 7: Spot Instance Management"
echo ""
echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
echo "What are Spot Instances?"
echo "  â€¢ Azure's spare capacity sold at 60-90% discount"
echo "  â€¢ Can be evicted with 30-second notice"
echo "  â€¢ Perfect for burst workloads"
echo ""
echo "Tensor Fusion Spot Handling:"
echo ""
echo "  1. Preemption Detection"
echo "     â€¢ Azure sends eviction notice (30s warning)"
echo "     â€¢ Platform immediately drains workloads"
echo "     â€¢ Migrates to other available GPUs"
echo ""
echo "  2. Graceful Degradation"
echo "     â€¢ If spot unavailable â†’ fallback to on-demand"
echo "     â€¢ Temporarily higher cost for reliability"
echo "     â€¢ Alert sent to ops team"
echo ""
echo "  3. Checkpointing"
echo "     â€¢ Long-running jobs checkpoint every 5 min"
echo "     â€¢ Resume on new GPU after eviction"
echo "     â€¢ No work lost"
echo ""
echo "  4. Cost Optimization"
echo "     â€¢ Mix: 70% spot, 30% on-demand"
echo "     â€¢ Balances cost vs reliability"
echo "     â€¢ Average savings: 55%"
echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
echo ""
sleep 3

# Step 8: Configuration example
info "âš™ï¸  Step 8: Complete Configuration Example"
echo ""
echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
cat << 'YAML'
apiVersion: tensor-fusion.ai/v1
kind: AzureGPUSource
metadata:
  name: production-burst
spec:
  # Azure Connection
  subscriptionID: "xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx"
  resourceGroup: "tf-production-rg"
  location: "eastus"
  
  # GPU Configuration
  vmSize: "Standard_NC24ads_A100_v4"  # NVIDIA A100
  priority: "Spot"
  maxPrice: "5.00"
  evictionPolicy: "Deallocate"
  
  # Auto-Scaling
  minInstances: 0
  maxInstances: 50
  targetUtilization: 0.75
  scaleUpThreshold: 0.80
  scaleDownThreshold: 0.30
  cooldownPeriod: "10m"
  
  # Cost Management
  maxMonthlyCost: "10000"
  costAlertThreshold: 0.80
  enableCostAlerts: true
  
  # Scheduling
  schedule:
    # Scale up before business hours
    scaleUp:
    - cron: "0 8 * * 1-5"  # 8 AM Mon-Fri
      instances: 10
    # Scale down after hours
    scaleDown:
    - cron: "0 18 * * 1-5"  # 6 PM Mon-Fri
      instances: 2
  
  # Networking
  virtualNetwork: "aks-production-vnet"
  subnet: "gpu-burst-subnet"
  networkSecurityGroup: "gpu-nsg"
  
  # Health & Monitoring
  healthCheckInterval: "30s"
  healthCheckTimeout: "10s"
  unhealthyThreshold: 3
  
  # Integration
  targetGPUPool: "default-pool"
  tags:
    environment: "production"
    cost-center: "ml-platform"
    auto-shutdown: "true"
YAML
echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
echo ""
sleep 2

# Step 9: Check existing sources
info "ğŸ“Š Step 9: Current Azure GPU Sources"
echo ""
AZURE_SOURCES=$(kubectl get azuregpusource --all-namespaces -o custom-columns=\
NAMESPACE:.metadata.namespace,\
NAME:.metadata.name,\
LOCATION:.spec.location,\
VM-SIZE:.spec.vmSize,\
MIN:.spec.minInstances,\
MAX:.spec.maxInstances 2>/dev/null)

if [ -n "$AZURE_SOURCES" ]; then
  echo "$AZURE_SOURCES"
else
  info "No Azure GPU sources configured yet"
  info "  Use the configuration above to create one"
fi
echo ""
sleep 2

# Summary
echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
success "ğŸ¯ Key Takeaways:"
echo "   âœ“ Cloud bursting reduces costs by 87% vs always-peak"
echo "   âœ“ Spot instances provide 60-90% discount on GPU costs"
echo "   âœ“ Auto-scaling handles traffic spikes automatically"
echo "   âœ“ Multi-region federation for global low latency"
echo "   âœ“ Graceful handling of spot instance evictions"
echo "   âœ“ Budget controls prevent cost overruns"
echo "   âœ“ Scheduled scaling for predictable patterns"
echo ""
info "ğŸ’¡ Use Case: Variable workloads, cost optimization, global platforms"
echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
echo ""

info "ğŸ’¡ Next Steps:"
echo "  1. Configure Azure credentials"
echo "  2. Create AzureGPUSource with your settings"
echo "  3. Test scaling: kubectl apply -f burst-config.yaml"
echo "  4. Monitor costs: kubectl describe azuregpusource <name>"
echo ""
info "Demo complete! Resources will be cleaned up automatically."
sleep 2

